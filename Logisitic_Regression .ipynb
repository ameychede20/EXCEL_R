{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtdqN1JR9PpwoVL3HVn8c5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","Bank\n","\n"],"metadata":{"id":"o_QwFsYVMZaJ"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","# Load the dataset\n","data_path = '/content/bank-full.csv'  # Update this path\n","bank_data = pd.read_csv(data_path, delimiter=';')\n","\n","# One-hot encode categorical variables\n","bank_data_encoded = pd.get_dummies(bank_data, drop_first=True)\n","\n","# Split the dataset into features (X) and the target variable (y)\n","X = bank_data_encoded.drop('y_yes', axis=1)\n","y = bank_data_encoded['y_yes']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize the models\n","models = {\n","    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n","    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=100),\n","    \"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=100)\n","}\n","\n","# Dictionary to hold evaluation metrics for each model\n","evaluation_metrics = {\n","    \"Model\": [],\n","    \"Accuracy\": [],\n","    \"Precision\": [],\n","    \"Recall\": [],\n","    \"F1 Score\": [],\n","    \"ROC AUC\": []\n","}\n","\n","# Train and evaluate each model\n","for name, model in models.items():\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    y_prob = model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n","\n","    # Update the evaluation metrics for each model\n","    evaluation_metrics[\"Model\"].append(name)\n","    evaluation_metrics[\"Accuracy\"].append(accuracy_score(y_test, y_pred))\n","    evaluation_metrics[\"Precision\"].append(precision_score(y_test, y_pred))\n","    evaluation_metrics[\"Recall\"].append(recall_score(y_test, y_pred))\n","    evaluation_metrics[\"F1 Score\"].append(f1_score(y_test, y_pred))\n","    evaluation_metrics[\"ROC AUC\"].append(roc_auc_score(y_test, y_prob))\n","\n","# Convert the metrics dictionary to a DataFrame for better presentation\n","evaluation_results_df = pd.DataFrame(evaluation_metrics)\n","print(evaluation_results_df)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKlAnZa2Medc","executionInfo":{"status":"ok","timestamp":1710972645806,"user_tz":420,"elapsed":23043,"user":{"displayName":"Amey Chede","userId":"03083119488680828454"}},"outputId":"82435327-4554-4263-b0c4-bf13663bf3c1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["                          Model  Accuracy  Precision    Recall  F1 Score  \\\n","0           Logistic Regression  0.897822   0.655493  0.322640  0.432432   \n","1      Random Forest Classifier  0.903351   0.659794  0.410632  0.506215   \n","2  Gradient Boosting Classifier  0.903572   0.656205  0.421632  0.513393   \n","\n","    ROC AUC  \n","0  0.900571  \n","1  0.925910  \n","2  0.920482  \n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"P2G8rNboNF2L"}}]}